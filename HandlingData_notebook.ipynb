{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a366e6fe",
   "metadata": {},
   "source": [
    "**Вам нужно изменить масштаб значений числового признака, чтобы они находились между двумя значениями.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bed6e353",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.28571429],\n",
       "       [0.35714286],\n",
       "       [0.42857143],\n",
       "       [1.        ]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "# Create feature\n",
    "feature = np.array([[-500.5],\n",
    "                    [-100.1],\n",
    "                    [0],\n",
    "                    [100.1],\n",
    "                    [900.9]])\n",
    "# Create scaler\n",
    "minmax_scale = preprocessing.MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_feature = minmax_scale.fit_transform(feature)\n",
    "# Show feature\n",
    "scaled_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f84b66",
   "metadata": {},
   "source": [
    "Минимальное-максимальное масштабирование использует\n",
    "минимальное и максимальное значения объекта для масштабирования значений в пределах диапазона.\n",
    "В частности, min-max вычисляет:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f97b18c",
   "metadata": {},
   "source": [
    "xi' = (xi-min(x))/(max(x)-min(x))\n",
    "\n",
    "[0,1,2,3] -> [0, 1/3, 2/3, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f10b313",
   "metadata": {},
   "source": [
    "scikit-learn MinMaxScaler предлагает два варианта масштабирования объекта. Один из вариантов\n",
    "- использовать fit для вычисления минимального и максимального значений объекта, а затем использовать transform для изменения масштаба объекта. \n",
    "- Второй вариант - использовать fit_transform для выполнения обеих операций одновременно. Математической разницы между этими двумя вариантами нет, но иногда есть практическая выгода в разделении операций, поскольку это позволяет нам применять одни и те же преобразование в различные наборы данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27cc83b",
   "metadata": {},
   "source": [
    "**Вы хотите преобразовать объект так, чтобы среднее значение было равно 0, а стандартное отклонение -1**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac009136",
   "metadata": {},
   "source": [
    "Стандартное отклонение – это статистическая единица, которая представляет собой вариацию данных, то есть отображает отклонение значений данных от центрального значения (среднего значения данных)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32b0416e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.76058269],\n",
       "       [-0.54177196],\n",
       "       [-0.35009716],\n",
       "       [-0.32271504],\n",
       "       [ 1.97516685]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature\n",
    "x = np.array([[-1000.1],\n",
    "[-200.2],\n",
    "[500.5],\n",
    "[600.6],\n",
    "[9000.9]])\n",
    "# Create scaler\n",
    "scaler = preprocessing.StandardScaler()\n",
    "# Transform the feature\n",
    "standardized = scaler.fit_transform(x)\n",
    "# Show feature\n",
    "standardized\n",
    "#standardized.mean() #4.4408920985006264e-17\n",
    "#standardized.std()  #1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c0d7f",
   "metadata": {},
   "source": [
    "xi' = (xi - <u>x</u>) / σ, где <u>x</u> -среднее"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dc34de",
   "metadata": {},
   "source": [
    "Если наши данные содержат значительные отклонения, это может негативно сказаться на нашей стандартизации, влияя на среднее значение и дисперсию признака. В этом случае часто бывает полезно\n",
    "вместо этого изменить масштаб объекта, используя медиану и квартильный диапазон.\n",
    "Квартиль - верхний - ниже - 75% признака; нижний - ниже - 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c64c77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.87387612],\n",
       "       [-0.875     ],\n",
       "       [ 0.        ],\n",
       "       [ 0.125     ],\n",
       "       [10.61488511]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "robust_scaler = preprocessing.RobustScaler()\n",
    "# Transform feature\n",
    "new = robust_scaler.fit_transform(x)\n",
    "new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab9413b",
   "metadata": {},
   "source": [
    "**Вы хотите изменить масштаб значений признаков наблюдений, чтобы они имели единичную норму (общая длина равна 1).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3e90384",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.70710678, 0.70710678],\n",
       "       [0.30782029, 0.95144452],\n",
       "       [0.07405353, 0.99725427],\n",
       "       [0.04733062, 0.99887928],\n",
       "       [0.95709822, 0.28976368]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "features = np.array([[0.5, 0.5],\n",
    "[1.1, 3.4],\n",
    "[1.5, 20.2],\n",
    "[1.63, 34.4],\n",
    "[10.9, 3.3]])\n",
    "# Create normalizer\n",
    "normalizer = Normalizer(norm=\"l2\")\n",
    "# Transform feature matrix\n",
    "normalizer.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd90b3c9",
   "metadata": {},
   "source": [
    "Многие методы масштабирования (например, минимальное-максимальное масштабирование и стандартизация) работают с\n",
    "объектами; однако мы также можем масштабировать отдельные наблюдения.\n",
    "Нормализатор масштабирует значения отдельных наблюдений таким образом, чтобы они имели единичную норму\n",
    "(сумма их длин равна 1). Этот тип масштабирования часто используется, когда у нас есть\n",
    "много эквивалентных функций (например, классификация текста, когда каждое слово или\n",
    "группа из n слов является функцией).\n",
    "Нормализатор предоставляет три варианта нормы с евклидовой нормой (часто называемой L2)\n",
    "в качестве аргумента по умолчанию:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a69e04f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.5       ],\n",
       "       [0.24444444, 0.75555556],\n",
       "       [0.06912442, 0.93087558],\n",
       "       [0.04524008, 0.95475992],\n",
       "       [0.76760563, 0.23239437]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform feature matrix\n",
    "features_l1_norm = Normalizer(norm=\"l1\").transform(features)\n",
    "# Show feature matrix\n",
    "features_l1_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81068610",
   "metadata": {},
   "source": [
    "Интуитивно норму L2 можно рассматривать как расстояние между двумя точками в\n",
    "Нью-Йорк для птицы (т.е. прямая линия), в то время как L1 можно рассматривать как\n",
    "расстояние для человека, идущего по улице (пройдите один квартал на север, один квартал на восток, один квартал\n",
    "на север, один квартал на восток и т.д.), вот почему это называется “Manhattan нормой” или “Taxicab norm”."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbc80159",
   "metadata": {},
   "source": [
    "**Вы хотите создать полиномиальные функции и функции взаимодействия.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa8486de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  3.,  1.,  3.,  9.],\n",
       "       [ 2.,  3.,  4.,  6.,  9.],\n",
       "       [ 4.,  6., 16., 24., 36.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# Create feature matrix\n",
    "features = np.array([[1, 3],\n",
    "[2, 3],\n",
    "[4, 6]])\n",
    "# Create PolynomialFeatures object\n",
    "polynomial_interaction = PolynomialFeatures(degree=2, include_bias=False)\n",
    "# Create polynomial features\n",
    "polynomial_interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6571c604",
   "metadata": {},
   "source": [
    "Полиномиальные объекты - это те объекты, которые создаются путем возведения существующих объектов в степень.\n",
    "\n",
    "Например, если набор данных имел один входной объект X, то полиномиальным объектом было бы добавление нового объекта (столбца), значения которого вычислялись путем возведения значений в квадрат в X, например X ^ 2. Этот процесс можно повторить для каждой входной переменной в наборе данных, создав преобразованную версию каждой.\n",
    "\n",
    "Как таковые, полиномиальные объекты являются одним из видов проектирования объектов, например, создание новых входных объектов на основе существующих объектов.\n",
    "\n",
    "“Степень” полинома используется для управления количеством добавляемых объектов, например, степень 3 добавит две новые переменные для каждой входной переменной. Обычно используется небольшая степень, например 2 или 3.\n",
    "Также часто добавляют новые переменные, которые представляют взаимодействие между объектами, например, новый столбец, представляющий одну переменную, умноженную на другую. Это тоже можно повторить для каждой входной переменной, создавая новую переменную “взаимодействия” для каждой пары входных переменных.\n",
    "\n",
    "Возведенная в квадрат или куб версия входной переменной изменит распределение вероятностей, разделяя малые и большие значения, разделение, которое увеличивается с увеличением размера экспоненты.\n",
    "\n",
    "Такое разделение может помочь некоторым алгоритмам машинного обучения делать лучшие прогнозы и является общим для задач моделирования с регрессионным прогнозом и, как правило, задач, которые имеют числовые входные переменные.\n",
    "\n",
    "Обычно линейные алгоритмы, такие как линейная регрессия и логистическая регрессия, хорошо реагируют на использование полиномиальных входных переменных.\n",
    "\n",
    "*Полиномиальная регрессия расширяет линейную модель за счет добавления дополнительных предикторов, полученных путем возведения каждого из исходных предикторов в степень. Например, кубическая регрессия использует три переменные, X, X2 и X3, в качестве предикторов. Этот подход обеспечивает простой способ обеспечить нелинейную подгонку к данным.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf0c22",
   "metadata": {},
   "source": [
    "Параметр degree определяет максимальную степень многочлена.\n",
    "Например, degree=2 создаст новые функции, возведенные во вторую степень:\n",
    "x1,x2,x1^2,x2^2\n",
    "\n",
    "Кроме того, по умолчанию PolynomialFeatures включает в себя функции взаимодействия:\n",
    "\n",
    "x1x2\n",
    "\n",
    "Мы можем ограничить созданные функции только функциями взаимодействия, установив значение\n",
    "interaction_only равным True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52afc20c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  3.,  3.],\n",
       "       [ 2.,  3.,  6.],\n",
       "       [ 4.,  6., 24.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interaction = PolynomialFeatures(degree=2,\n",
    "interaction_only=True, include_bias=False)\n",
    "interaction.fit_transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454a18d9",
   "metadata": {},
   "source": [
    "Полиномиальные объекты часто создаются, когда мы хотим включить представление о том, что\n",
    "существует нелинейная взаимосвязь между объектами и целью.\n",
    "Например, мы могли бы заподозрить, что влияние возраста на вероятность наличия серьезного заболевания не является постоянным с течением времени, а увеличивается с возрастом. \n",
    "Мы можем закодировать этот непостоянный эффект в объекте x, сгенерировав формы этого объекта более высокого порядка (x2, x3 и т.д.).\n",
    "\n",
    "Кроме того, часто мы сталкиваемся с ситуациями, когда эффект одной функции зависит от другой функции. \n",
    "Простым примером было бы, если бы мы пытались\n",
    "предсказать, был ли наш кофе сладким или нет, и у нас были две характеристики: 1) был ли\n",
    "кофе размешан или нет, и 2) добавили ли мы сахар. По отдельности каждая характеристика\n",
    "не предсказывает сладость кофе, но комбинация их эффектов предсказывает. То\n",
    "есть кофе был бы сладким только в том случае, если бы в нем был сахар и он был размешан.\n",
    "Влияние каждого признака на целевой показатель (сладость) зависит друг от друга. Мы\n",
    "можем закодировать эту взаимосвязь, включив функцию взаимодействия, которая является\n",
    "продуктом отдельных функций."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bddbcf",
   "metadata": {},
   "source": [
    "**Вы хотите выполнить пользовательское преобразование для одного или нескольких объектов.**\n",
    "В scikit-learn используйте FunctionTransformer, чтобы применить функцию к набору\n",
    "функций:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "79a9005d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[12, 13],\n",
       "       [12, 13],\n",
       "       [12, 13]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer\n",
    "# Create feature matrix\n",
    "features = np.array([[2, 3],\n",
    "[2, 3],\n",
    "[2, 3]])\n",
    "# Define a simple function\n",
    "def add_ten(x):\n",
    "    return x + 10\n",
    "# Create transformer\n",
    "ten_transformer = FunctionTransformer(add_ten)\n",
    "# Transform feature matrix\n",
    "ten_transformer.transform(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af85848f",
   "metadata": {},
   "source": [
    "Мы можем создать такое же преобразование в pandas, используя apply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "499e7d59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2\n",
       "0         12         13\n",
       "1         12         13\n",
       "2         12         13"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(features, columns=[\"feature_1\", \"feature_2\"])\n",
    "# Apply function\n",
    "df.apply(add_ten)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9621028",
   "metadata": {},
   "source": [
    "Обычно возникает желание внести некоторые пользовательские преобразования в один или несколько\n",
    "объектов. Например, мы могли бы захотеть создать объект, который является естественным логарифмом\n",
    "значений другого объекта. Мы можем сделать это, создав функцию и затем\n",
    "сопоставив ее с функциями, используя либо FunctionTransformer от scikit-learn, либо\n",
    "apply от pandas. В решении мы создали очень простую функцию add_ten,\n",
    "которая добавляла 10 к каждому входному сигналу, но нет причин, по которым мы не могли бы определить гораздо\n",
    "более сложную функцию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f3e2c5",
   "metadata": {},
   "source": [
    "**Вы хотите выявить экстремальные наблюдения (выбросы).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa834ada",
   "metadata": {},
   "source": [
    "Обнаружение выбросов, к сожалению, является скорее искусством, чем наукой. Однако\n",
    "распространенный метод состоит в том, чтобы предположить, что данные распределены нормально, и на основе этого\n",
    "предположения “нарисовать” эллипс вокруг данных, классифицируя любое наблюдение внутри\n",
    "эллипса как входное (помеченное как 1), а любое наблюдение за пределами эллипса как\n",
    "выброс (помеченный как -1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d016ad30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1,  1,  1,  1,  1,  1,  1,  1,  1,  1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.datasets import make_blobs\n",
    "# Create simulated data\n",
    "\n",
    "features, _ = make_blobs(n_samples = 10, \n",
    "                #Общее количество сэмплов, которые нужно сгенерировать.\n",
    "n_features = 2, #Количество функций для каждого образца.\n",
    "                         \n",
    "centers = 1, #1 выборка or Количество центров выборки \n",
    "#(категорий), которые необходимо создать, или определенная центральная точка.\n",
    "random_state = 1) \n",
    "#\n",
    "# Замените значения первого наблюдения экстремальными значениями\n",
    "features[0,0] = 10000\n",
    "features[0,1] = 10000\n",
    "# Create detector\n",
    "outlier_detector = EllipticEnvelope(contamination=.1)\n",
    "# Fit detector\n",
    "outlier_detector.fit(features)\n",
    "# Predict outliers\n",
    "outlier_detector.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1792bd5",
   "metadata": {},
   "source": [
    "Основным ограничением этого подхода является необходимость указания\n",
    "параметра загрязнения, который представляет собой долю наблюдений, являющихся выбросами, — значение, которое мы не знаем. Думайте о загрязнении как о нашей оценке чистоты\n",
    "наших данных. Если мы ожидаем, что в наших данных будет мало выбросов, мы можем установить загрязнение\n",
    "на что-то незначительное. Однако, если мы считаем, что данные, скорее всего, содержат\n",
    "выбросы, мы можем установить для них более высокое значение.\n",
    "\n",
    "Вместо того чтобы рассматривать наблюдения в целом, мы можем вместо этого рассмотреть отдельные\n",
    "признаки и определить экстремальные значения в этих признаках, используя межквартильный диапазон\n",
    "(IQR):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33af709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one feature\n",
    "feature = features[:,0]\n",
    "# Create a function to return index of outliers\n",
    "def indicies_of_outliers(x):\n",
    "q1, q3 = np.percentile(x, [25, 75])\n",
    "iqr = q3 - q1\n",
    "lower_bound = q1 - (iqr * 1.5)\n",
    "upper_bound = q3 + (iqr * 1.5)\n",
    "return np.where((x > upper_bound) | (x < lower_bound))\n",
    "# Run function\n",
    "indicies_of_outliers(feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab496d0",
   "metadata": {},
   "source": [
    "IQR - это разница между первым и третьим квартилем набора данных. Вы можете\n",
    "думать о IQR как о разбросе основной массы данных, при этом выбросы представляют\n",
    "собой наблюдения вдали от основной концентрации данных. Выбросы обычно\n",
    "определяются как любое значение, на 1,5 МКР меньше первого квартиля или на 1,5 МКР больше\n",
    "третьего квартиля.\n",
    "\n",
    "Не существует единого наилучшего метода обнаружения выбросов. Вместо этого у нас есть\n",
    "набор методик, каждая из которых имеет свои преимущества и недостатки. Наша\n",
    "лучшая стратегия часто заключается в том, чтобы испробовать несколько методов (например, как EllipticEnvelope, так\n",
    "и обнаружение на основе IQR) и посмотреть на результаты в целом.\n",
    "Если это вообще возможно, мы должны взглянуть на наблюдения, которые мы обнаруживаем как выбросы, и\n",
    "попытаться понять их. Например, если у нас есть набор данных о домах и один особенностью является количество комнат, является ли выброс со 100 номерами действительно домом или это\n",
    "на самом деле отель, который был неправильно классифицирован?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71be957",
   "metadata": {},
   "source": [
    "**Обработка выбросов**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e14810",
   "metadata": {},
   "source": [
    "Обычно у нас есть три стратегии, которые мы можем использовать для обработки выбросов. Во-первых, мы можем\n",
    "отбросить их:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5f27f14f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Price  Bathrooms  Square_Feet\n",
       "0  534433        2.0         1500\n",
       "1  392333        3.5         2500\n",
       "2  293222        2.0         1500"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create DataFrame\n",
    "houses = pd.DataFrame()\n",
    "houses['Price'] = [534433, 392333, 293222, 4322032]\n",
    "houses['Bathrooms'] = [2, 3.5, 2, 116]\n",
    "houses['Square_Feet'] = [1500, 2500, 1500, 48000]\n",
    "# Filter observations\n",
    "houses[houses['Bathrooms'] < 20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1111804c",
   "metadata": {},
   "source": [
    "Во-вторых, мы можем пометить их как выбросы и включить это в качестве функции:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ebbcdc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "      <th>Outlier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Bathrooms  Square_Feet  Outlier\n",
       "0   534433        2.0         1500        0\n",
       "1   392333        3.5         2500        0\n",
       "2   293222        2.0         1500        0\n",
       "3  4322032      116.0        48000        1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Create feature based on boolean condition\n",
    "houses[\"Outlier\"] = np.where(houses[\"Bathrooms\"] < 20, 0, 1)\n",
    "# Show data\n",
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf1888c",
   "metadata": {},
   "source": [
    "Наконец, мы можем преобразовать функцию, чтобы ослабить эффект выброса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "58366887",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Bathrooms</th>\n",
       "      <th>Square_Feet</th>\n",
       "      <th>Outlier</th>\n",
       "      <th>Log_Of_Square_Feet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>534433</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>392333</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.824046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>293222</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1500</td>\n",
       "      <td>0</td>\n",
       "      <td>7.313220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4322032</td>\n",
       "      <td>116.0</td>\n",
       "      <td>48000</td>\n",
       "      <td>1</td>\n",
       "      <td>10.778956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Price  Bathrooms  Square_Feet  Outlier  Log_Of_Square_Feet\n",
       "0   534433        2.0         1500        0            7.313220\n",
       "1   392333        3.5         2500        0            7.824046\n",
       "2   293222        2.0         1500        0            7.313220\n",
       "3  4322032      116.0        48000        1           10.778956"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log feature\n",
    "houses[\"Log_Of_Square_Feet\"] = [np.log(x) for x in houses[\"Square_Feet\"]]\n",
    "# Show data\n",
    "houses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2927c2",
   "metadata": {},
   "source": [
    "Подобно обнаружению выбросов, не существует жесткого правила для их обработки.\n",
    "То, как мы с ними справляемся, должно основываться на двух аспектах. Во-первых, мы должны рассмотреть, что выделяет их из общей массы.\n",
    "Если мы считаем, что это ошибки в данных, например,\n",
    "из-за неисправности датчика или неправильно закодированного значения, тогда мы можем исключить наблюдение\n",
    "или заменить значения выбросов на NaN, поскольку мы не можем поверить этим значениям. Однако,\n",
    "если мы считаем, что выбросы являются подлинными экстремальными значениями (например, house [mansion]\n",
    "с 200 ванными комнатами), затем помечая их как выбросы или изменяя их значения это более уместно.\n",
    "\n",
    "Во-вторых, то, как мы обрабатываем выбросы, должно основываться на нашей цели машинного\n",
    "обучения. Например, если мы хотим спрогнозировать цены на жилье на основе характеристик дома\n",
    ", мы могли бы разумно предположить, что цена на особняки с более чем 100\n",
    "ванными комнатами определяется иной динамикой, чем на обычные семейные дома.\n",
    "Более того, если мы разрабатываем модель для использования в рамках онлайн-заявки на получение ипотечного кредита\n",
    ", мы могли бы предположить, что среди наших потенциальных пользователей не будет\n",
    "миллиардеров, желающих купить особняк.\n",
    "\n",
    "Итак, что нам следует делать, если у нас есть выбросы? Подумайте о том, почему они являются выбросами,\n",
    "имейте в виду конечную цель для данных и, самое главное, помните, что *непринятие решения об устранении выбросов само по себе является решением, имеющим последствия.*\n",
    "\n",
    "Еще один момент: если у вас действительно есть выбросы, стандартизация может оказаться\n",
    "неуместной, поскольку выбросы могут сильно влиять на среднее значение и дисперсию\n",
    ". В этом случае используйте метод масштабирования, более надежный по отношению к выбросам, таким как\n",
    "RobustScaler."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acede174",
   "metadata": {},
   "source": [
    "**Дискретизирующие функции**\n",
    "\n",
    "**У вас есть числовой признак, и вы хотите разбить его на отдельные ячейки.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246ccd3d",
   "metadata": {},
   "source": [
    "В зависимости от того, как мы хотим разбить данные, мы\n",
    "можем использовать два метода. Во-первых, мы можем бинаризировать функцию в соответствии с некоторым пороговым значением:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9c727bf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import Binarizer\n",
    "# Create feature\n",
    "age = np.array([[6],\n",
    "[12],\n",
    "[20],\n",
    "[36],\n",
    "[65]])\n",
    "# Create binarizer\n",
    "binarizer = Binarizer(threshold=18)\n",
    "# Transform feature\n",
    "binarizer.fit_transform(age)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1981237f",
   "metadata": {},
   "source": [
    "Во-вторых, мы можем разбить числовые характеристики в соответствии с несколькими пороговыми значениями:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b72258a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bin feature\n",
    "np.digitize(age, bins=[20,30,64])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9822d24e",
   "metadata": {},
   "source": [
    "!!! в группах числа меньше порогового значения\n",
    "\n",
    "Обратите внимание, что аргументы для параметра bins обозначают левый край каждой ячейки.\n",
    "Например, аргумент 20 не включает элемент со значением 20,\n",
    "только два значения меньше 20. Мы можем изменить это поведение, установив\n",
    "для параметра right значение True:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "63cb198f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [2],\n",
       "       [3]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.digitize(age, bins=[20,30,64], right=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b73627",
   "metadata": {},
   "source": [
    "Дискретизация может быть плодотворной стратегией, когда у нас есть основания полагать, что\n",
    "числовой признак должен вести себя больше как категориальный признак. Например,\n",
    "мы могли бы полагать, что существует очень небольшая разница в привычках тратить деньги у 19- и\n",
    "20-летних, но значительная разница между 20- и 21-летними (возраст\n",
    "в Соединенных Штатах, когда молодые люди могут употреблять алкоголь). В этом примере было\n",
    "бы полезно разделить людей в наших данных на тех, кто может употреблять\n",
    "алкоголь, и тех, кто не может. Аналогично, в других случаях может оказаться\n",
    "полезным распределить наши данные по трем или более ячейкам."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c882da56",
   "metadata": {},
   "source": [
    "**Группировка наблюдений с использованием кластеризации**\n",
    "\n",
    "**Вы хотите сгруппировать наблюдения таким образом, чтобы похожие наблюдения были сгруппированы\n",
    "вместе.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beea20dd",
   "metadata": {},
   "source": [
    "Если известно, что есть к групп, можно сгруппировать похожие наблюдения с помощью кластеризации к-средних"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c484e075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plokmit/anaconda3/envs/myenvconda/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-9.877554</td>\n",
       "      <td>-3.336145</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-7.287210</td>\n",
       "      <td>-8.353986</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-6.943061</td>\n",
       "      <td>-7.023744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.440167</td>\n",
       "      <td>-8.791959</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-6.641388</td>\n",
       "      <td>-8.075888</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  group\n",
       "0  -9.877554  -3.336145      2\n",
       "1  -7.287210  -8.353986      0\n",
       "2  -6.943061  -7.023744      0\n",
       "3  -7.440167  -8.791959      0\n",
       "4  -6.641388  -8.075888      0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "# Make simulated feature matrix\n",
    "features, _ = make_blobs(n_samples = 50,\n",
    "n_features = 2,\n",
    "centers = 3,\n",
    "random_state = 1)\n",
    "# Create DataFrame\n",
    "dataframe = pd.DataFrame(features, columns=[\"feature_1\", \"feature_2\"])\n",
    "# Make k-means clusterer\n",
    "clusterer = KMeans(3, random_state=0)\n",
    "# Fit clusterer\n",
    "clusterer.fit(features)\n",
    "# Predict values\n",
    "dataframe[\"group\"] = clusterer.predict(features)\n",
    "# View first few observations\n",
    "dataframe.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e659496",
   "metadata": {},
   "source": [
    "**Удаление наблюдений с пропущенными значениями**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1d38987d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.1, 11.1],\n",
       "       [ 2.2, 22.2],\n",
       "       [ 3.3, 33.3],\n",
       "       [ 4.4, 44.4]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create feature matrix\n",
    "features = np.array([[1.1, 11.1],\n",
    "[2.2, 22.2],\n",
    "[3.3, 33.3],\n",
    "[4.4, 44.4],\n",
    "[np.nan, 55]])\n",
    "# Keep only observations that are not (denoted by ~) missing\n",
    "features[~np.isnan(features).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be418935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.1</td>\n",
       "      <td>11.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.2</td>\n",
       "      <td>22.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.3</td>\n",
       "      <td>33.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.4</td>\n",
       "      <td>44.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2\n",
       "0        1.1       11.1\n",
       "1        2.2       22.2\n",
       "2        3.3       33.3\n",
       "3        4.4       44.4"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "dataframe = pd.DataFrame(features, columns=[\"feature_1\", \"feature_2\"])\n",
    "# Remove observations with missing values\n",
    "dataframe.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339b86ef",
   "metadata": {},
   "source": [
    "Большинство алгоритмов машинного обучения не могут обработать какие-либо пропущенные значения в целевых\n",
    "массивах и массивах объектов. По этой причине мы не можем игнорировать пропущенные значения в наших данных\n",
    "и должны устранить проблему во время предварительной обработки.\n",
    "Самое простое решение - удалить каждое наблюдение, содержащее одно или несколько\n",
    "пропущенных значений, задача, быстро и легко решаемая с помощью NumPy или pandas.\n",
    "Тем не менее, мы должны очень неохотно удалять наблюдения с пропущенными\n",
    "значениями. Удаление их является основным вариантом, поскольку наш алгоритм теряет доступ к\n",
    "информации, содержащейся в не пропущенных значениях наблюдения."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a7f946",
   "metadata": {},
   "source": [
    "Существует три типа недостающих\n",
    "данных:\n",
    "\n",
    "Пропущено совершенно случайным образом (MCAR)\n",
    "Вероятность того, что значение отсутствует, не зависит ни от чего.\n",
    "Например, респондентка бросает кубик, прежде чем ответить на вопрос: если она\n",
    "бросает шестерку, она пропускает этот вопрос.\n",
    "\n",
    "Пропущенный наугад (МАРТ)\n",
    "Вероятность того, что значение отсутствует, не является полностью случайной, но\n",
    "зависит от информации, собранной в других функциях. Например, в ходе опроса\n",
    "задается вопрос о гендерной идентичности и годовой заработной плате, и женщины с большей вероятностью\n",
    "пропускают вопрос о зарплате; однако их отсутствие ответа зависит только от информация, которую мы зафиксировали в нашей функции гендерной идентичности.\n",
    "\n",
    "Пропущенный не случайно (MNAR)\n",
    "Вероятность того, что значение отсутствует, не случайна и зависит от\n",
    "информации, не отраженной в наших функциях. Например, в опросе задается вопрос о\n",
    "гендерной идентичности, и женщины с большей вероятностью пропускают вопрос о зарплате, а\n",
    "в наших данных нет элемента гендерной идентичности.\n",
    "Иногда допустимо удалять наблюдения, если они относятся к MCAR или MAR.\n",
    "\n",
    "Однако, если значение равно MNAR, тот факт, что значение отсутствует, сам\n",
    "по себе является информацией. Удаление наблюдений MNAR может внести искажение в наши данные, поскольку\n",
    "мы удаляем наблюдения, вызванные каким-либо ненаблюдаемым систематическим эффектом."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4426d745",
   "metadata": {},
   "source": [
    "*Identifying the Three Types of Missing Data*\n",
    "\n",
    "*Missing-Data Imputation*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0623e26a",
   "metadata": {},
   "source": [
    "**Вычисление пропущенных значений**\n",
    "\n",
    "У вас в данных отсутствуют значения, и вы хотите заполнить или спрогнозировать их значения.\n",
    "\n",
    "Если у вас небольшой объем данных, спрогнозируйте недостающие значения, используя k-ближайших\n",
    "соседей (KNN):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dd94ab9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.05837272,  4.48825769],\n",
       "       [-8.60973869, -3.72714879],\n",
       "       [ 1.37129721,  5.23107449],\n",
       "       ...,\n",
       "       [-1.91854276,  4.59578307],\n",
       "       [-1.79600465,  4.28743568],\n",
       "       [-6.97684609, -8.89498834]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузить библиотеку\n",
    "from sklearn.impute import KNNImputer\n",
    "# Make a simulated feature matrix\n",
    "features, _ = make_blobs(n_samples = 1000,\n",
    "n_features = 2,\n",
    "random_state = 1)\n",
    "scaler = StandardScaler()\n",
    "standardized_features = scaler.fit_transform(features)\n",
    "# Заменить первое значение первого признака на пропущенное значение\n",
    "true_value = standardized_features[0,0]\n",
    "standardized_features[0,0] = np.nan\n",
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8adddd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = KNNImputer(n_neighbors=2, weights=\"uniform\")\n",
    "knn_impost = imputer.fit_transform(standardized_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "66b87459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8730186113995938\n",
      "1.165654174300821\n"
     ]
    }
   ],
   "source": [
    "print(true_value)\n",
    "print(knn_impost[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6db569b",
   "metadata": {},
   "source": [
    "Класс SimpleImputer предоставляет основные стратегии для восстановления отсутствующих значений. Пропущенные значения могут быть восстановлены с использованием предоставленного постоянного значения или с использованием статистики (среднего, медианного или наиболее частого) каждого столбца, в котором находятся пропущенные значения. Этот класс также допускает различные кодировки пропущенных значений.\n",
    "\n",
    "Следующий фрагмент демонстрирует, как заменить отсутствующие значения, закодированные как np.nan, с использованием среднего значения столбцов (ось 0), содержащих отсутствующие значения:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "af899cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузить библиотеку\n",
    "# Make a simulated feature matrix\n",
    "features, _ = make_blobs(n_samples = 1000,\n",
    "n_features = 2,\n",
    "random_state = 1)\n",
    "scaler = StandardScaler()\n",
    "standardized_features = scaler.fit_transform(features)\n",
    "# Заменить первое значение первого признака на пропущенное значение\n",
    "true_value = standardized_features[0,0]\n",
    "standardized_features[0,0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2a029c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8730186113995938\n",
      "-6.197770033577906\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "imp.fit(features)\n",
    "X = standardized_features\n",
    "result = imp.transform(X)\n",
    "print(true_value)\n",
    "print(result[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ff7f2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8730186113995938\n",
      "-4.319738139110626\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "imp.fit(features)\n",
    "X_test = standardized_features\n",
    "# the model learns that the second feature is double the first\n",
    "print(true_value)\n",
    "print(imp.transform(X_test)[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4896214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
