{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94c785e3",
   "metadata": {},
   "source": [
    "# Работа с категориальными данными"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973c3c8a",
   "metadata": {},
   "source": [
    "Наборы категорий без внутреннего упорядочения называются номинальными. Примеры номинальных категорий\n",
    "включают:\n",
    "\n",
    "- синий, красный, зеленый;\n",
    "- мужчина, женщина;\n",
    "- банан, клубника, яблоко.\n",
    "\n",
    "С другой стороны, когда набор категорий имеет некое естественное упорядочение,\n",
    "мы называем его порядковым. Например:\n",
    "- низкий, средний, высокий;\n",
    "- молодые, старые;\n",
    "- согласен, нейтрален, не согласен."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691fccec",
   "metadata": {},
   "source": [
    "**Кодирование\n",
    "номинальных категориальных признаков**\n",
    "\n",
    "Дан признак с номинальными классами, который не имеет внутренней упорядоченности (например, яблоко, груша, банан)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ea1770",
   "metadata": {},
   "source": [
    "Преобразовать признак в кодировку с одним активным состоянием1 с помощью\n",
    "класса LabeiBinarizer библиотеки scikit-leam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e0d4ad2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 1, 0, 0],\n",
       "       [0, 0, 1, 0]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Импортировать библиотеки\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "# Создать признак\n",
    "feature = np.array([[\"Texas\"],\n",
    "[\"California\"],\n",
    "[\"Texas\"],\n",
    "[\"Delaware\"],\n",
    "[\"Moscow\"]])\n",
    "# Создать кодировщик одного активного состояния\n",
    "one_hot = LabelBinarizer()\n",
    "# Преобразовать признак\n",
    "# в кодировку с одним активным состоянием\n",
    "one_hot.fit_transform (feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2159cef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>California</th>\n",
       "      <th>Delaware</th>\n",
       "      <th>Moscow</th>\n",
       "      <th>Texas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   California  Delaware  Moscow  Texas\n",
       "0       False     False   False   True\n",
       "1        True     False   False  False\n",
       "2       False     False   False   True\n",
       "3       False      True   False  False\n",
       "4       False     False    True  False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Импортировать библиотеку\n",
    "import pandas as pd\n",
    "# Создать фиктивные переменные из признака\n",
    "pd.get_dummies(feature[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce329dd",
   "metadata": {},
   "source": [
    "Одной из полезных возможностей библиотеки scikit-leam является обработка\n",
    "ситуации, когда в каждом наблюдении перечисляется несколько классов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "457dd49e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 1, 1],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 1],\n",
       "       [0, 0, 1, 1, 0],\n",
       "       [1, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создать мультиклассовый признак\n",
    "multiclass_feature = [(\"Texas\", \"Florida\"), \n",
    "                      (\"California\", \"Alabama\"), \n",
    "                      (\"Texas\", \"Florida\"), \n",
    "                      (\"Delware\", \"Florida\"), \n",
    "                      (\"Texas\", \"Alabama\")]\n",
    "# Создать мультиклассовый кодировщик, преобразующий признак\n",
    "# в кодировку с одним активным состоянием\n",
    "one_hot_multiclass = MultiLabelBinarizer()\n",
    "# Кодировать мультиклассовый признак\n",
    "# в кодировку с одним активным состоянием\n",
    "one_hot_multiclass.fit_transform(multiclass_feature)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55bd292",
   "metadata": {},
   "source": [
    "Можно подумать, что правильная стратегия состоит в том, чтобы назначать каждому классу числовое значение (например, Texas = 1, California = 2). Однако, когда\n",
    "классы не имеют внутренней упорядоченности (например, Техас не \"меньше\"\n",
    "Калифорнии), числовые значения ошибочно создают порядок, которого нет."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "005ba075",
   "metadata": {},
   "source": [
    "**Кодирование\n",
    "порядковых категориальных признаков**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5565e5a",
   "metadata": {},
   "source": [
    "Дан порядковый категориальный признак (например, высокий, средний, низкий).\n",
    "Выполнить его кодировку.\n",
    "\n",
    "Использовать метод replace фрейма данных pandas для преобразования строковых\n",
    "меток в числовые эквиваленты:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b44eade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    2\n",
       "4    3\n",
       "Name: оценка, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузить библиотеку\n",
    "import pandas as pd\n",
    "# Создать признаки\n",
    "dataframe = pd.DataFrame({\"оценка\": [\"низкая\", \"низкая\",\n",
    "\"средняя\", \"средняя\", \"высокая\"]})\n",
    "#Создать словарь преобразования шкалы\n",
    "scale_mapper = {\"низкая\":1,\n",
    "\"средняя\":2,\n",
    "\"высокая\":3}\n",
    "#Заменить значения признаков значениями словаря\n",
    "dataframe[\"оценка\"].replace(scale_mapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aea9fde",
   "metadata": {},
   "source": [
    "**Кодирование словарей признаков**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1a9b8c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 2., 4.],\n",
       "       [0., 4., 3.],\n",
       "       [2., 1., 0.],\n",
       "       [2., 2., 0.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Импортировать библиотеку\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "# Создать словарь\n",
    "data_dict = [{\"красный\": 2, \"синий\": 4},\n",
    "{\"красный\": 4, \"синий\": 3},\n",
    "{\"красный\": 1, \"желтый\": 2},\n",
    "{\"красный\": 2, \"желтый\": 2}]\n",
    "# Создать векторизатор словаря\n",
    "dictvectorizer = DictVectorizer(sparse=False)\n",
    "# Конвертировать словарь в матрицу признаков\n",
    "features = dictvectorizer.fit_transform(data_dict)\n",
    "# Взглянуть на матрицу признаков\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6177ada5",
   "metadata": {},
   "source": [
    "По умолчанию Dictvectorizer выводит разреженную матрицу, в которой хранятся\n",
    "только элементы со значением, отличным от 0. Это может быть очень полезно,\n",
    "когда имеются массивные матрицы (часто встречающиеся в обработке естественного языка) и требуется минимизировать потребности в оперативной памяти. Мы\n",
    "можем заставить Dictvectorizer вывести плотную матрицу, используя sparse=False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "62b478fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['желтый', 'красный', 'синий'], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Имена каждого созданного признака можно получить с помощью метода\n",
    "#get_feature_names:\n",
    "# Получить имена признаков\n",
    "feature_names = dictvectorizer.get_feature_names_out()\n",
    "# Взглянуть на имена признаков\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8655911d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>желтый</th>\n",
       "      <th>красный</th>\n",
       "      <th>синий</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   желтый  красный  синий\n",
       "0     0.0      2.0    4.0\n",
       "1     0.0      4.0    3.0\n",
       "2     2.0      1.0    0.0\n",
       "3     2.0      2.0    0.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Создать фрейм данных из признаков\n",
    "pd.DataFrame(features, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e5c9c1",
   "metadata": {},
   "source": [
    "Словарь является популярной структурой данных, используемой многими языками\n",
    "программирования; однако машинно-обучающиеся алгоритмы ожидают, что данные будут в виде матрицы. Конвертировать словарь в матрицу можно, используя\n",
    "объект dictvectorizer библиотеки scikit-leam.\n",
    "Такая ситуация является обычной во время обработки естественного языка. Например, дана коллекция документов, и для каждого документа имеется словарь, содержащий количество вхождений каждого слова в документ. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036d67db",
   "metadata": {},
   "source": [
    "В нашем игрушечном примере имеется всего три уникальных слова (красный, желтый,\n",
    "синий), поэтому в нашей матрице всего три признака; однако вы можете себе представить, что если бы каждый документ был на самом деле книгой в университетской библиотеке, то наша матрица признаков была бы очень большой (и тогда потребовалось бы установить параметр разреженности sparse в True)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fd06eb",
   "metadata": {},
   "source": [
    "**Импутация пропущенных значений классов**\n",
    "\n",
    "Дан категориальный признак, содержащий пропущенные значения, которые требуется заменить предсказанными значениями."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4673aa02",
   "metadata": {},
   "source": [
    "Идеальное решение — натренировать машинно-обучающийся классификационный\n",
    "алгоритм для предсказания пропущенных значений, обычно классификатор к ближайших соседей (KNN):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "960857da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузить библиотеки\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Создать матрицу признаков с категориальным признаком\n",
    "X = np.array([[0, 2.10, 1.45],\n",
    "            [1, 1.18, 1.33],\n",
    "            [0, 1.22, 1.27],\n",
    "            [1, -0.21, -1.19]])\n",
    "# Создать матрицу признаков\n",
    "# с отсутствующими значениями в категориальном признаке\n",
    "X_with_nan = np.array([[np.nan, 0.87, 1.31],\n",
    "[np.nan, -0.67, -0.22]])\n",
    "# Натренировать ученика KNN\n",
    "elf = KNeighborsClassifier(3, weights='distance')\n",
    "trained_model = elf.fit(X[:,1:], X [:,0])\n",
    "# Предсказать класс пропущенных значений\n",
    "imputed_values = trained_model.predict(X_with_nan[:, 1:])\n",
    "imputed_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a788b341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 1.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Соединить столбец предсказанного класса с другими признаками\n",
    "X_with_imputed = np.hstack((imputed_values.reshape(-1,1), X_with_nan[:,1:]))\n",
    "# Соединить две матрицы признаков\n",
    "np.vstack((X_with_imputed, X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7695d7",
   "metadata": {},
   "source": [
    "Альтернативным решением является заполнение пропущенных значений наиболее\n",
    "частыми значениями признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ba820be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.87,  1.31],\n",
       "       [ 0.  , -0.67, -0.22],\n",
       "       [ 0.  ,  2.1 ,  1.45],\n",
       "       [ 1.  ,  1.18,  1.33],\n",
       "       [ 0.  ,  1.22,  1.27],\n",
       "       [ 1.  , -0.21, -1.19]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "# Соединить две матрицы признаков\n",
    "X_complete = np.vstack((X_with_nan, X))\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "imputer.fit_transform(X_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d462871d",
   "metadata": {},
   "source": [
    "# Работа с несбалансированными классами"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee9665",
   "metadata": {},
   "source": [
    "- Собрать больше данных. \n",
    "- Если это невозможно, то изменить метрические показатели, используемые для оценивания модели.\n",
    "- Если это не работает, рассмотреть возможность использования встроенных в модель параметров веса классов (если таковые имеются), делая понижающий или повышающий отбор. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf590a9",
   "metadata": {},
   "source": [
    "Для того чтобы продемонстрировать наши решения, нам нужно создать немного\n",
    "данных с несбалансированными классами. Набор данных ирисов Фишера содержит\n",
    "три сбалансированных класса по 50 наблюдений, каждый из которых указывает на\n",
    "вид цветка — ирис щетинистый (Iris setosa), ирис виргинский {Iris virginica) и ирис\n",
    "разноцветный (Iris versicolor). Для того чтобы разбалансировать набор данных, мы\n",
    "удаляем 40 из 50 наблюдений ириса щетинистого, а затем объединяем классы ирис\n",
    "виргинский и ирис разноцветный. Конечным результатом является бинарный вектор целей, указывающий на то, является ли наблюдение цветком ириса щетинистого или нет. Результатом станут 10 наблюдений ирис щетинистый (класс 0) и\n",
    "100 наблюдений не ирис щетинистый (класс 1):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0fac0b38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'iris.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузить библиотеки\n",
    "import numpy as пр\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "# Загрузить данные цветков ириса Фишера\n",
    "iris = load_iris()\n",
    "# Создать матрицу признаков\n",
    "features = iris.data\n",
    "# Создать вектор целей\n",
    "target = iris.target\n",
    "# Удалить первые 40 наблюдений\n",
    "features = features[40:,:]\n",
    "target = target[40:]\n",
    "# Создать бинарный вектор целей, указывающий, является ли класс 0\n",
    "target = np.where((target == 0), 0, 1)\n",
    "# Взглянуть на несбалансированный вектор целей\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4412bd96",
   "metadata": {},
   "source": [
    "**Превышение/Up-Выборка класса меньшинств**\n",
    "При расширенной выборке выборки из классов меньшинств дублируются случайным образом, чтобы достичь эквивалентности классу большинства. Существует множество методов, используемых для достижения этой цели."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6114d0c5",
   "metadata": {},
   "source": [
    "1. Using scikit-learn:\n",
    "\n",
    "Это можно сделать, импортировав модуль повторной выборки из scikit-learn.\n",
    "Syntax: sklearn.utils.resample(*arrays, replace=True, n_samples=None, random_state=None, stratify=None)\n",
    "Параметры:\n",
    "\n",
    "- *arrays: Замена фрейма данных/списков/массивов\n",
    "\n",
    "- replace: : реализует повторную выборку с заменой или без нее. Логический тип значения. Значение по умолчанию - True.\n",
    "\n",
    "- n_samples: количество генерируемых выборок. Значение по умолчанию - None. Если значение равно None, то автоматически берется первое измерение массива. Это значение не будет больше длины массивов, если для параметра replace задано значение False.\n",
    "\n",
    "- random_state: используется для перетасовки данных. Если задано положительное ненулевое число, то оно перетасовывается, в противном случае нет. Значение по умолчанию - None.\n",
    "\n",
    "- stratify: данные разбиваются стратифицированным образом, если установлено значение True. Значение по умолчанию - None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fc57b28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_classes=2, \n",
    "                           weights=[0.8, 0.2],\n",
    "                           n_features=4, \n",
    "                           n_samples=100, \n",
    "                           random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ec6e9",
   "metadata": {},
   "source": [
    "Вот основные входные параметры для функции make_classification():\n",
    "\n",
    "- n_samples: Сколько наблюдений вы хотите сгенерировать?\n",
    "- n_features Количество числовых признаков.\n",
    "- n_informative: Количество ‘полезных’ функций. Только эти функции передают сигнал, который ваша модель будет использовать для классификации набора данных.\n",
    "- n_classes: Количество уникальных классов (значений) для целевой метки.\n",
    "- Divided in 2 classes in a ratio of 80:20 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "043413b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X, columns = [\n",
    "    \"name_1\",\n",
    "    'name_2',\n",
    "    'name_3',\n",
    "    'name_4',\n",
    "])\n",
    "df['balance']=y\n",
    "df_major = df[df['balance'] == 0]\n",
    "df_minor = df[df['balance'] == 1]\n",
    "len(df_major) #80\n",
    "len(df_minor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1f81bd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_minor_sample = resample(df_minor,\n",
    "                             \n",
    "                           # Upsample with replacement\n",
    "                           replace=True,    \n",
    "                             \n",
    "                           # Number to match majority class\n",
    "                           n_samples=80,   \n",
    "                           random_state=42)\n",
    "len(df_minor_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9f2485a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "balance\n",
       "0    80\n",
       "1    80\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = pd.concat([df_major, df_minor_sample])\n",
    "df_sample['balance'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f95c582",
   "metadata": {},
   "source": [
    "*Объяснение :*\n",
    "\n",
    "- Во-первых, мы разделим точки данных из каждого класса на отдельные фреймы данных.\n",
    "- После этого класс меньшинства подвергается повторной выборке с заменой путем установки количества точек данных, эквивалентного количеству точек большинства.\n",
    "- В конце концов, мы объединим исходный фрейм данных класса majority и фрейм данных класса minority с увеличенной выборкой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d6c3d5",
   "metadata": {},
   "source": [
    "2. Using RandomOverSampler:\n",
    "\n",
    "Это можно сделать с помощью метода RandomOverSampler, присутствующего в imblearn. Эта функция случайным образом генерирует новые точки данных, принадлежащие классу меньшинства, с заменой (по умолчанию).\n",
    "\n",
    "Одна проблема со случайной наивной избыточной выборкой заключается в том, что **она просто дублирует уже существующие данные.** Поэтому, хотя алгоритмы классификации подвергаются большему количеству наблюдений из класса меньшинства, они не узнают больше о том, как отличить наблюдения. Новые данные не содержат больше информации о характеристиках, чем старые данные."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1d8f85d",
   "metadata": {},
   "source": [
    "Syntax: RandomOverSampler(sampling_strategy=’auto’, random_state=None, shrinkage=None)\n",
    "\n",
    "Parameters:\n",
    "    \n",
    "- sampling_strategy: Выборка информации для набора данных.Некоторые значения - ‘minority’: только класс меньшинства, ‘not minority’: все классы, кроме класса меньшинства, ‘not majority’: все классы, кроме класса большинства, ‘all’: все классы, ‘auto’: аналогично ‘not majority’, значение по умолчанию ‘auto’\n",
    "- random_state: Используется для перетасовки данных. Если задано положительное ненулевое число, то оно перетасовывается, в противном случае нет. Значение по умолчанию - None.\n",
    "- shrinkage:: параметр, управляющий усадкой. Значения следующие: float: Коэффициент усадки, применяемый ко всем классам. диктант: Каждый класс будет иметь определенный коэффициент усадки. Нет: Усадка= 0. Значение по умолчанию - None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d6d39d82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([80, 20]))"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.datasets import make_classification\n",
    "import numpy as np\n",
    "# Making Dataset having 100\n",
    "# dummy samples with 4 features \n",
    "# Divided in 2 classes in a ratio of 80:20 \n",
    "X, y = make_classification(n_classes=2, \n",
    "                           weights=[0.8, 0.2],\n",
    "                           n_features=4, \n",
    "                           n_samples=100, \n",
    "                           random_state=42)\n",
    "  \n",
    "# Printing number of samples in\n",
    "# each class before Over-Sampling\n",
    "np.unique(y, return_counts=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "59145a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([80, 80]))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Over Sampling Minority class\n",
    "OverS = RandomOverSampler(random_state=42)\n",
    "  \n",
    "# Fit predictor (x variable)\n",
    "# and target (y variable) using fit_resample()\n",
    "X_Over, Y_Over = OverS.fit_resample(X, y)\n",
    "  \n",
    "# Printing number of samples in\n",
    "# each class after Over-Sampling\n",
    "np.unique(Y_Over, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab59013",
   "metadata": {},
   "source": [
    "**3. Synthetic Minority Oversampling Technique (SMOTE):**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23c69b5",
   "metadata": {},
   "source": [
    "SMOTE используется для генерации искусственных / синтетических сэмплов для класса меньшинств. Этот метод работает путем случайного выбора выборки из класса меньшинства и определения K-ближайших соседей для этой выборки, затем искусственная выборка добавляется между выбранной выборкой и ее соседями. Эта функция присутствует в модуле imblearn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de8da38",
   "metadata": {},
   "source": [
    "Syntax: SMOTE(sampling_strategy=’auto’, random_state=None, k_neighbors=5, n_jobs=None)\n",
    "\n",
    "Parameters:\n",
    "- sampling_strategy: Выборка информации для набора\n",
    "данных \n",
    "- random_state: Используется для перетасовки данных. Если задано положительное ненулевое число, то оно перетасовывается, в противном случае нет. Значение по умолчанию - None.\n",
    "- k_neighbors: Количество ближайших соседей, используемых для генерации искусственных/синтетических выборок. Значение по умолчанию - 5\n",
    "- n_jobs: количество используемых ядер процессора. Значение по умолчанию - None. None здесь означает 1, а не 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "d7400e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([80, 20]))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing imblearn, scikit-learn library\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Создание набора данных, имеющего\n",
    "# 100 фиктивных образцов с 4 функциями\n",
    "# Разделить на 2 сорта в соотношении 80:20\n",
    "X, y = make_classification(n_classes=2,\n",
    "\t\t\t\t\t\tweights=[0.8, 0.2],\n",
    "\t\t\t\t\t\tn_features=4,\n",
    "\t\t\t\t\t\tn_samples=100,\n",
    "\t\t\t\t\t\trandom_state=42)\n",
    "\n",
    "# Печать количества образцов в\n",
    "# каждый класс перед повторной выборкой\n",
    "np.unique(y, return_counts=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "81576523",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([80, 80]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Создание экземпляра класса SMOTE\n",
    "# Для избыточной выборки класса меньшинств\n",
    "smote = SMOTE()\n",
    "\n",
    "# Fit predictor (x variable)\n",
    "# and target (y variable) using fit_resample()\n",
    "X_OverSmote, Y_OverSmote = smote.fit_resample(X, y)\n",
    "\n",
    "# Printing number of samples\n",
    "# in each class after Over-Sampling\n",
    "np.unique(Y_Over, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd1fbdc",
   "metadata": {},
   "source": [
    "Класс меньшинства задается в качестве входного вектора.\n",
    "Определите его K-ближайших соседей\n",
    "Выберите одного из этих соседей и поместите искусственную точку выборки в любом месте между соседом и рассматриваемой точкой выборки.\n",
    "Повторяйте до тех пор, пока набор данных не будет сбалансирован."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0885b1",
   "metadata": {},
   "source": [
    "*Недостатки чрезмерной выборки:\n",
    "Повышенные шансы на чрезмерную подгонку по мере создания дубликатов класса меньшинства*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d77045",
   "metadata": {},
   "source": [
    "**Класс большинства с низкой выборкой**\n",
    "\n",
    "Понижающая выборка - это процесс случайного отбора выборок класса большинства и удаления их, чтобы предотвратить их доминирование над классом меньшинства в наборе данных."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbda7cab",
   "metadata": {},
   "source": [
    "1. Использование scikit-learn :\n",
    "Это похоже на повышающую выборку и может быть выполнено путем импорта модуля повторной выборки из scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0cf22457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    feature_1  feature_2  feature_3  feature_4  balance\n",
      "0   -1.053839  -1.027544  -0.329294   0.826007        1\n",
      "1    1.569317   1.306542  -0.239385  -0.331376        0\n",
      "2   -0.658926  -0.357633   0.723682  -0.628277        0\n",
      "3   -0.136856   0.460938   1.896911  -2.281386        0\n",
      "4   -0.048629   0.502301   1.778730  -2.171053        0\n",
      "..        ...        ...        ...        ...      ...\n",
      "95  -2.241820  -1.248690   2.357902  -2.009185        0\n",
      "96   0.573042   0.362054  -0.462814   0.341294        1\n",
      "97  -0.375121  -0.149518   0.588465  -0.575002        0\n",
      "98   1.042518   1.058239   0.461945  -0.984846        0\n",
      "99  -0.121203  -0.043997   0.204211  -0.203119        0\n",
      "\n",
      "[100 rows x 5 columns]\n",
      "balance\n",
      "0    20\n",
      "1    20\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Importing scikit-learn, pandas library\n",
    "from sklearn.utils import resample\n",
    "from sklearn.datasets import make_classification\n",
    "import pandas as pd\n",
    "\n",
    "# Making DataFrame having\n",
    "# 100 dummy samples with 4 features\n",
    "# Divided in 2 classes in a ratio of 80:20\n",
    "X, y = make_classification(n_classes=2,\n",
    "\t\t\t\t\t\tweights=[0.8, 0.2],\n",
    "\t\t\t\t\t\tn_features=4,\n",
    "\t\t\t\t\t\tn_samples=100,\n",
    "\t\t\t\t\t\trandom_state=42)\n",
    "\n",
    "df = pd.DataFrame(X, columns=['feature_1',\n",
    "\t\t\t\t\t\t\t'feature_2',\n",
    "\t\t\t\t\t\t\t'feature_3',\n",
    "\t\t\t\t\t\t\t'feature_4'])\n",
    "df['balance'] = y\n",
    "print(df)\n",
    "\n",
    "# Let df represent the dataset\n",
    "# Dividing majority and minority classes\n",
    "df_major = df[df.balance==0]\n",
    "df_minor = df[df.balance==1]\n",
    "\n",
    "# Down sampling majority class\n",
    "df_major_sample = resample(df_major,\n",
    "\t\t\treplace=False, # Down sample without replacement\n",
    "\t\t\tn_samples=20, # Number to match minority class\n",
    "\t\t\trandom_state=42)\n",
    "\n",
    "# Combine down sampled majority class and minority class\n",
    "df_sample = pd.concat([df_major_sample, df_minor])\n",
    "\n",
    "# Display count of data points in both class\n",
    "df_sample.balance.value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef07f13",
   "metadata": {},
   "source": [
    "Объяснение :\n",
    "\n",
    "Во-первых, мы разделим точки данных из каждого класса на отдельные фреймы данных.\n",
    "После этого производится повторная выборка класса большинства без замены путем установки количества точек данных, эквивалентного количеству точек меньшинства.\n",
    "В конце мы объединим исходный фрейм данных класса меньшинства и фрейм данных класса большинства с пониженной выборкой."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10768e7",
   "metadata": {},
   "source": [
    "2. Использование RandomUnderSampler\n",
    "Это можно сделать с помощью метода RandomUnderSampler, присутствующего в imblearn. Эта функция случайным образом выбирает подмножество данных для класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "cb43e32f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([80, 20]))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing imblearn library\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Making Dataset having\n",
    "# 100 dummy samples with 4 features\n",
    "# Divided in 2 classes in a ratio of 80:20\n",
    "X, y = make_classification(n_classes=2,\n",
    "\t\t\t\t\t\tweights=[0.8, 0.2],\n",
    "\t\t\t\t\t\tn_features=4,\n",
    "\t\t\t\t\t\tn_samples=100,\n",
    "\t\t\t\t\t\trandom_state=42)\n",
    "\n",
    "# Printing number of samples\n",
    "# in each class before Under-Sampling\n",
    "np.unique(y, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9764f90a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([20, 20]))"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Down-Sampling majority class\n",
    "UnderS = RandomUnderSampler(random_state=42, replacement=True)\n",
    "\n",
    "# Fit predictor (x variable)\n",
    "# and target (y variable) using fit_resample()\n",
    "X_Under, Y_Under = UnderS.fit_resample(X, y)\n",
    "\n",
    "# Printing number of samples in\n",
    "# each class after Under-Sampling\n",
    "np.unique(Y_Under, return_counts=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d418efd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d92683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
